Output_dimension = ((Input_dimension - Kernel_size + 2 * Padding) / Stride) + 1
For a convolution operation, we can calculate the output dimensions using the formula:

Image 1024x768, 3 channels:
Input: (3, 1024, 768)
Kernel: 5x5
Padding: 1
Stride: 2
Output channels: 16
Width calculation: ((1024 - 5 + 21) / 2) + 1 = 511
Height calculation: ((768 - 5 + 21) / 2) + 1 = 383
Output tensor dimensions: (16, 511, 383)


Image 1920x1080, 3 channels:
Input: (3, 1920, 1080)
Same parameters as above
Width calculation: ((1920 - 5 + 21) / 2) + 1 = 959
Height calculation: ((1080 - 5 + 21) / 2) + 1 = 539
Output tensor dimensions: (16, 959, 539)


Image 1920x1080, 8 channels:
No, we cannot apply this convolution to an image with 8 input channels. The number of input channels in the image must match the input channel dimension of the convolution kernel. The kernel has 3 input channels, so it can only be applied to images with exactly 3 channels. The kernel dimensions would be (16, 3, 5, 5) where:
16 is the number of output channels
3 is the number of input channels
5x5 is the kernel size
To work with an 8-channel image, we would need to modify the convolution to have a kernel with dimensions (16, 8, 5, 5).